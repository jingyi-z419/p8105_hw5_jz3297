---
title: "Homework 5"
author: Jingyi Zhang
output: github_document
---

```{r, include = FALSE}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
          
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```


## Problem 1

Read in the data.

```{r}
homicide_df =
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

Let's look at this a bit.

```{r}
aggregate_df =  
  homicide_df %>%
  group_by(city_state) %>%
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy() # gives you a tidy version of statistical results
```

Try to iterate ......

```{r}
results_df =
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)), # map two inputs
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x)) # tidy version of the tests
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>%
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



```{r, error = TRUE}
city_prop_test = function(df) {
  
  
  n_unsolved ...
  n_total ...
  
  prop.test()
  
  
}


homicide_df =
  read_csv("data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```


## Problem 2

Create a tidy dataframe containing all file names.

```{r, error = TRUE}
path_df =
  tibble(
    path = list.files(path = "lda_data"),
    ) %>% 
  mutate(
    path = str_c("lda_data/", path),
    data = map(path, read_csv)) %>%
  unnest(data)
```


```{r}
lda_df =
  path_df %>%
    mutate(
      subject_id = str_remove(path, "lda_data/"),
      subject_id = str_remove(subject_id, ".csv")
    ) %>% 
    select(subject_id, week_1:week_8)

lda_df
```


```{r}
lda_df =
  lda_df %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "measurement"
  )

lda_df
```


Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

```{r}
ggplot(lda_df, aes(x = week, y = measurement, group = subject_id, color = subject_id)) +
  geom_point() +
  geom_line()
```



<br />

## Problem 3

Create a function with fixed n =30, sigma = 5.

```{r}
sim_mean_t = function(n = 30, mu, sigma = 5) { #default sample size and sd
  
  sim_data =
    tibble(
     x = rnorm(n, mean = mu, sd = sigma)
    )
  
  sim_data %>%
    summarize(
      mu_hat = mean(x),
      t_test = t.test(x, mu = 0, conf.level = 0.95) %>% 
        broom::tidy() %>% 
        select(p.value)
  )
  
}
```

Set mu = 0, generate 5000 dataset from a normal distribution.

```{r}
set.seed(7)
sim_results =   
  rerun(5000, sim_mean_t(mu = 0)) %>% 
  bind_rows() %>% 
  mutate(p_value = t_test$p.value) %>% 
  select(mu_hat, p_value)

sim_results
```

Repeat the same process for mu = 1,2,3,4,5,6

```{r}
set.seed(7)
sim_results =
  tibble(
    mu = c(0, 1, 2, 3, 4, 5, 6)
  ) %>% 
  mutate(
    output_lists = map(.x = mu, ~rerun(5000, sim_mean_t(mu = .x))),
    estimate_results_df = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(estimate_results_df)

sim_results =
  sim_results %>% 
  mutate(p_value = t_test$p.value) %>% 
  select(mu_hat, p_value)

sim_results
```

Make a plot showing the power of the test. Describe the association between effect size and power.


```{r}

```


Make a plot showing the average estimate of mu hat on the y axis and the true value of mu on the x axis. 

```{r}

```

Make a second plot showing the average estimate of mu hat only in samples for which the null was rejected on the y axis and the true value of mu on the x axis.

```{r}

```

Is the sample average of mu across tests for which the null is rejected approximately equal to the true value of mu? Why or why not?


